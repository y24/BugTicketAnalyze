# å¿…è¦ãªå†ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import (
    classification_report,
    confusion_matrix,
    ConfusionMatrixDisplay,
)
from sklearn.model_selection import learning_curve

# åˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆ
def display_classification_report(y_test, y_pred, target_labels):
    print("ğŸ“‹ Classification Report:")
    print(classification_report(y_test, y_pred, target_names=target_labels))

# æ··åŒè¡Œåˆ—ã®å¯è¦–åŒ–
def plot_confusion_matrix(y_test, y_pred, labels):
    cm = confusion_matrix(y_test, y_pred)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)
    disp.plot(cmap="Blues")
    plt.title("æ··åŒè¡Œåˆ—ï¼ˆConfusion Matrixï¼‰")
    plt.xlabel("äºˆæ¸¬ãƒ©ãƒ™ãƒ«")
    plt.ylabel("å®Ÿéš›ã®ãƒ©ãƒ™ãƒ«")
    plt.show()

# å­¦ç¿’æ›²ç·šã®æç”»
def plot_learning_curve(model, X, y, scoring='f1_weighted', cv=5):
    train_sizes, train_scores, test_scores = learning_curve(
        model, X, y, cv=cv, scoring=scoring,
        train_sizes=np.linspace(0.1, 1.0, 5), shuffle=True, random_state=42
    )
    train_mean = train_scores.mean(axis=1)
    test_mean = test_scores.mean(axis=1)

    plt.plot(train_sizes, train_mean, label="è¨“ç·´ã‚¹ã‚³ã‚¢")
    plt.plot(train_sizes, test_mean, label="æ¤œè¨¼ã‚¹ã‚³ã‚¢")
    plt.xlabel("è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®ã‚µã‚¤ã‚º")
    plt.ylabel(f"{scoring}")
    plt.title("å­¦ç¿’æ›²ç·šï¼ˆLearning Curveï¼‰")
    plt.legend()
    plt.grid(True)
    plt.show()

# ç‰¹å¾´é‡ã®é‡è¦åº¦ï¼ˆãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆ + TF-IDF ã®å ´åˆï¼‰
def show_feature_importance(model, vectorizer, top_n=10):
    try:
        importances = model.feature_importances_
        feature_names = vectorizer.get_feature_names_out()
        top_indices = importances.argsort()[-top_n:][::-1]
        print(f"ğŸ“Œ ä¸Šä½ {top_n} ã®é‡è¦ç‰¹å¾´é‡:")
        for i in top_indices:
            print(f"{feature_names[i]}: {importances[i]:.4f}")
    except AttributeError:
        print("ã“ã®ãƒ¢ãƒ‡ãƒ«ã§ã¯ç‰¹å¾´é‡ã®é‡è¦åº¦ã‚’å–å¾—ã§ãã¾ã›ã‚“ã€‚")
